{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOO3N07IjeJEMXJMtB/JTX5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishanmorwal/Rock-Paper-Scissors/blob/main/RockPaperScissors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement\n",
        "We all know and enjoy Stone,Paper,Scissors. It is a very popular game and rightfully so, for its simplicity yet enjoyability is off the charts. This model here, is an image classification model to classify an image as either the image of a stone or a paper or a scissors in the Sign Language."
      ],
      "metadata": {
        "id": "YlutL9IJhSah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1OoDUe4khRrf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the imports, we download the dataset and unzip it."
      ],
      "metadata": {
        "id": "UYbg44xdgtw5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Bz4cIADyfUIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb5432fb-d4c4-4bc1-b812-e69f1f60a38c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-09 07:35:10--  https://storage.googleapis.com/download.tensorflow.org/data/rps.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.207, 142.250.141.207, 142.251.2.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 200682221 (191M) [application/zip]\n",
            "Saving to: ‘/tmp/Rock-paper-scissors.zip’\n",
            "\n",
            "/tmp/Rock-paper-sci 100%[===================>] 191.38M   211MB/s    in 0.9s    \n",
            "\n",
            "2024-02-09 07:35:11 (211 MB/s) - ‘/tmp/Rock-paper-scissors.zip’ saved [200682221/200682221]\n",
            "\n",
            "paper  rock  scissors  training  validation\n"
          ]
        }
      ],
      "source": [
        "# prompt: download and unzip the kaggle stone-paper-scissors dataset\n",
        "!wget --no-check-certificate \\\n",
        "\"https://storage.googleapis.com/download.tensorflow.org/data/rps.zip\"\\\n",
        "-O \"/tmp/Rock-paper-scissors.zip\"\n",
        "lzip = '/tmp/Rock-paper-scissors.zip'\n",
        "zip_ref = zipfile.ZipFile(lzip,'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "!ls /tmp/rps"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is now downloaded and stored within the /tmp directory and is extracted. Within it, there"
      ],
      "metadata": {
        "id": "JchTdE6_jro2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_path = '/tmp/rps'\n",
        "\n",
        "src_path_rock     = os.path.join(src_path,'rock')\n",
        "src_path_paper    = os.path.join(src_path,'paper')\n",
        "src_path_scissors = os.path.join(src_path,'scissors')\n",
        "\n",
        "\n",
        "# Prints out the number of images in the sub-directories\n",
        "print(f\"There are {len(os.listdir(src_path_rock))} images of Rock in sign language.\")\n",
        "print(f\"There are {len(os.listdir(src_path_paper))} images of Paper in sign language.\")\n",
        "print(f\"There are {len(os.listdir(src_path_scissors))} images of Scissors in sign language.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--D80SGPkNFv",
        "outputId": "eeacfc33-841e-4800-dd1d-ab3025c076b2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 840 images of Rock in sign language.\n",
            "There are 840 images of Paper in sign language.\n",
            "There are 840 images of Scissors in sign language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we divide the data contained into training and validation directories."
      ],
      "metadata": {
        "id": "W7tK04Y-m0yD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/tmp/rps'\n",
        "\n",
        "# Makes sure directory is empty\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "# This function takes the root as argument and creates the directories\n",
        "\n",
        "def create_train_val_dirs(root_path):\n",
        "  os.makedirs(os.path.join(root_path,'training'))\n",
        "  os.makedirs(os.path.join(root_path,'validation'))\n",
        "  os.makedirs(os.path.join(root_path,'training/rock'))\n",
        "  os.makedirs(os.path.join(root_path,'training/paper'))\n",
        "  os.makedirs(os.path.join(root_path,'training/scissors'))\n",
        "  os.makedirs(os.path.join(root_path,'validation/rock'))\n",
        "  os.makedirs(os.path.join(root_path,'validation/paper'))\n",
        "  os.makedirs(os.path.join(root_path,'validation/scissors'))\n",
        "\n",
        "try:\n",
        "  create_train_val_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"Only happens if the root_dir is not empty, which should not be the case here.\")"
      ],
      "metadata": {
        "id": "JrjGxoL0m9o4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For testing the above code:\n",
        "\n",
        "for rootdir,dirs,files in os.walk(root_dir):\n",
        "  for subdir in dirs:\n",
        "    print(os.path.join(rootdir,subdir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFb-IwSHn685",
        "outputId": "b68b4f68-5e44-460b-867a-c06a5e33f445"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/rps/training\n",
            "/tmp/rps/validation\n",
            "/tmp/rps/training/scissors\n",
            "/tmp/rps/training/paper\n",
            "/tmp/rps/training/rock\n",
            "/tmp/rps/validation/scissors\n",
            "/tmp/rps/validation/paper\n",
            "/tmp/rps/validation/rock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next logical step here, is to split the data to populate the various directories in a random fashion. We do that using a `split_data` function, which takes the source directory, the training and validation directories as the arguments, along with a `split_size` as well, which determines the ratio of images used for training versus validation.\n",
        "\n",
        "Plus, to maintain the correctness of our dataset, we need to put in place a check that ensures that there are no files that have zero-length."
      ],
      "metadata": {
        "id": "CzAj8dS-oO_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(SOURCE_DIR,TRAINING_DIR,VALIDATION_DIR,SPLIT_SIZE):\n",
        "  filtered_files = []\n",
        "\n",
        "  for file_name in os.listdir(SOURCE_DIR):\n",
        "    file_path = os.path.join(SOURCE_DIR,file_name)\n",
        "    if os.path.getsize(file_name):\n",
        "      filtered_files.appened(file_name)\n",
        "    else:\n",
        "      print(f\"{file_name} is zero length, therefore not used\")\n",
        "\n",
        "  random_files = random.sample(filtered_files,len(filtered_files))\n",
        "  split = int(SPLIT_SIZE*len(filtered_files))\n",
        "  training_files = random_files[:split]\n",
        "  validation_files = random_files[split:]\n",
        "\n",
        "  for file_name in training_files:\n",
        "    copyfile(os.path.join(SOURCE_DIR,file_name),os.path.join(TRAINING_DIR))\n",
        "\n",
        "  for file_name in validation_files:\n",
        "    copyfile(os.path.join(SOURCE_DIR,file_name),os.path.join(VALIDATION_DIR))"
      ],
      "metadata": {
        "id": "jduS-VXlo1TF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That was just the division of data into Training and Validation directories. Now, we set up the directories of the three classes, Rock, Paper and Scissors."
      ],
      "metadata": {
        "id": "X3vuX_Xtp5oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROCK_SOURCE_DIR    = \"/tmp/rps/rock\"\n",
        "PAPER_SOURCE_DIR   = \"/tmp/rps/paper\"\n",
        "SCISSORS_SOURCE_DIR = \"/tmp/rps/scissors\"\n",
        "\n",
        "TRAINING_DIR   = \"/tmp/rps/training/\"\n",
        "VALIDATION_DIR = \"/tmp/rps/validation/\"\n",
        "\n",
        "TRAINING_ROCK_DIR       = os.path.join(TRAINING_DIR,\"rock/\")\n",
        "VALIDATION_ROCK_DIR     = os.path.join(VALIDATION_DIR,\"rock/\")\n",
        "TRAINING_PAPER_DIR      = os.path.join(TRAINING_DIR,\"paper/\")\n",
        "VALIDATION_PAPER_DIR    = os.path.join(VALIDATION_DIR,\"paper/\")\n",
        "TRAINING_SCISSORS_DIR   = os.path.join(TRAINING_DIR,\"scissors/\")\n",
        "VALIDATION_SCISSORS_DIR = os.path.join(VALIDATION_DIR,\"scissors/\")\n",
        "\n",
        "# Ensures the directories are empty in case of multiple uses of this code\n",
        "\n",
        "if len(os.listdir(TRAINING_ROCK_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_ROCK_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_PAPER_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_PAPER_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_SCISSORS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_SCISSORS_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "if len(os.listdir(VALIDATION_ROCK_DIR))>0:\n",
        "  for file in os.scandir(VALIDATION_ROCK_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_PAPER_DIR))>0:\n",
        "  for file in os.scandir(VALIDATION_PAPER_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_SCISSORS_DIR))>0:\n",
        "  for file in os.scandir(VALIDATION_SCISSORS_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "# Specify the split ratio\n",
        "split_size = .9\n",
        "\n",
        "# Running the function\n",
        "split_data(ROCK_SOURCE_DIR,TRAINING_ROCK_DIR,VALIDATION_ROCK_DIR,split_size)\n",
        "split_data(PAPER_SOURCE_DIR,TRAINING_PAPER_DIR,VALIDATION_PAPER_DIR,split_size)\n",
        "split_data(SCISSORS_SOURCE_DIR,TRAINING_SCISSORS_DIR,VALIDATION_SCISSORS_DIR,split_size)\n",
        "\n",
        "print(f\"\\nThere are {len(os.listdir(TRAINING_ROCK_DIR))} images of rock-sign for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_PAPER_DIR))} images of paper-sign for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_SCISSORS_DIR))} images of scissors-sign for training\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_ROCK_DIR))} images of rock-sign for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_PAPER_DIR))} images of paper-sign for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_SCISSORS_DIR))} images of scissors-sign for validation\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "9oAxWGkJqJb_",
        "outputId": "15660fb9-05e7-460e-a16b-25ff1d17aa29"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/tmp/rps/rock'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-e7d1ca5333fe>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Running the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROCK_SOURCE_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRAINING_ROCK_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVALIDATION_ROCK_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPAPER_SOURCE_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRAINING_PAPER_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVALIDATION_PAPER_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSCISSORS_SOURCE_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRAINING_SCISSORS_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVALIDATION_SCISSORS_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-153900100341>\u001b[0m in \u001b[0;36msplit_data\u001b[0;34m(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mfiltered_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSOURCE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSOURCE_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/rps/rock'"
          ]
        }
      ]
    }
  ]
}